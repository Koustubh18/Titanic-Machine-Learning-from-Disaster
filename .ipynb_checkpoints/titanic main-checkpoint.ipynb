{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "from scipy.stats import norm, skew\n",
    "from scipy.special import boxcox1p\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "# pd.set_option('display.max_rows', None)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import RobustScaler,StandardScaler\n",
    "from sklearn.model_selection import KFold, cross_val_score, ShuffleSplit,cross_validate\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier,AdaBoostClassifier,ExtraTreesClassifier,BaggingClassifier,VotingClassifier\n",
    "\n",
    "import warnings\n",
    "def ignore_warn(*args, **kwargs):\n",
    "    pass\n",
    "warnings.warn = ignore_warn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('train.csv')\n",
    "df_test = pd.read_csv('test.csv')\n",
    "\n",
    "df_test_PassengerId = df_test['PassengerId']\n",
    "\n",
    "df = pd.concat([df_train,df_test],ignore_index=True)\n",
    "df.drop(['PassengerId','Cabin','Ticket'],inplace = True,axis = 1)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fill NaN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Embarked'].fillna(df['Embarked'].mode()[0],inplace = True)\n",
    "df['Fare'].fillna(df[df['Pclass'] == 3]['Fare'].mean(),inplace = True)\n",
    "df['Age'].fillna(df['Age'].median(),inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['FamilySize'] = df['Parch'] + df['SibSp'] + 1\n",
    "\n",
    "df['FamilySize_Cat'] = 'Alone'\n",
    "df[(df['FamilySize']>=2) & (df['FamilySize']<=4)]['FamilySize_Cat'] = 'Small' \n",
    "df[(df['FamilySize']>=5) & (df['FamilySize']<=6)]['FamilySize_Cat'] = 'Medium' \n",
    "df[df['FamilySize']>=7]['FamilySize_Cat'] = 'Large' \n",
    "\n",
    "df['FareBin'] = pd.qcut(df['Fare'], 4)\n",
    "df['AgeBin'] = pd.cut(df['Age'], 5)\n",
    "\n",
    "df['Title'] = df['Name'].str.split(\", \", expand=True)[1].str.split(\".\", expand=True)[0]\n",
    "title_count = df['Title'].value_counts()\n",
    "df['Title'] = df['Title'].apply(lambda x: 'Misc' if title_count[x]<10 else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop('Name',axis = 1,inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy_col = ['Embarked','Sex','FamilySize_Cat','FareBin','AgeBin','Title']\n",
    "\n",
    "for feature in dummy_col:\n",
    "    df_ = pd.get_dummies(df[feature],prefix = feature,drop_first=True)\n",
    "    df.drop(feature,inplace = True,axis = 1)\n",
    "    df = pd.concat([df,df_],axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_train = len(df_train)\n",
    "corrmat = df.iloc[:n_train,:].corr()\n",
    "top_corr_features = corrmat.index[abs(corrmat[\"Survived\"])>0.1]\n",
    "plt.figure(figsize=(10,10))\n",
    "g = sns.heatmap(df.iloc[:n_train,:][top_corr_features].corr(),annot=True,cmap=\"RdYlGn\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Continious Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "continuous_features = [feature for feature in df.columns if len(df[feature].unique())>10 and df[feature].dtype != 'object']\n",
    "continuous_features,len(continuous_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sk = df[continuous_features].apply(lambda x:skew(x)).sort_values(ascending = False)\n",
    "sk = pd.DataFrame(sk)\n",
    "sk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ch = [0,0.03,0.05,0.08,0.1,0.13,0.15]\n",
    "df__ = pd.DataFrame()\n",
    "for choice in ch:\n",
    "    df_ = pd.DataFrame(skew(boxcox1p(df[continuous_features],choice)),columns=[choice],index = continuous_features)\n",
    "    df__ = pd.concat([df__,df_],axis = 1)\n",
    "    \n",
    "df__ = pd.concat([pd.DataFrame(skew(df[continuous_features]),columns = ['Org'],index = continuous_features),df__],axis = 1)\n",
    "\n",
    "\n",
    "skew_result = {}\n",
    "for i in df__.index:\n",
    "    min_ = 'Org'\n",
    "    for j in df__.columns:\n",
    "        if df__.loc[i,j]>=0 and df__.loc[i,j]<df__.loc[i,min_]:\n",
    "            min_ = j\n",
    "            \n",
    "    skew_result[i] = min_\n",
    "    \n",
    "\n",
    "print(skew_result)\n",
    "skew_result = {k:v for k,v in skew_result.items() if v != 'Org'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k,v in skew_result.items():\n",
    "    df[k] = boxcox1p(df[k],v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df.iloc[:n_train,:]\n",
    "df_test = df.iloc[n_train:,:]\n",
    "\n",
    "x = df_train.drop('Survived',axis = 1)\n",
    "y = df_train['Survived']\n",
    "df_test.drop('Survived',axis = 1,inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Validation\n",
    "ss = ShuffleSplit(n_splits = 10, test_size = .3, train_size = .6, random_state = 0 )\n",
    "\n",
    "def acc(model):\n",
    "    cvs = (cross_validate(model,x.values,y.values,cv = ss,return_train_score = True))\n",
    "    return cvs['train_score'].mean(),cvs['test_score'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cf1 = XGBClassifier(learning_rate= 0.01, max_depth= 4, n_estimators= 300, seed= 0)\n",
    "cf2 = AdaBoostClassifier(learning_rate= 0.1, n_estimators= 300, random_state= 0)\n",
    "cf3 = GradientBoostingClassifier(learning_rate= 0.05, max_depth= 2, n_estimators= 300,random_state= 0)\n",
    "cf4 = RandomForestClassifier(criterion= 'entropy', max_depth= 6, n_estimators= 100, oob_score= True, random_state= 0)\n",
    "cf5 = ExtraTreesClassifier(criterion= 'entropy', max_depth= 6, n_estimators= 100, random_state= 0)\n",
    "cf6 = BaggingClassifier(max_samples= 0.25, n_estimators= 300, random_state= 0)\n",
    "\n",
    "clf = [('xgb',cf1),('ada',cf2),('gbm',cf3),('rf',cf4),('et',cf5),('bbc',cf6)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ens_hard = VotingClassifier(estimators=clf,voting='hard')\n",
    "ens_soft = VotingClassifier(estimators=clf,voting='soft')\n",
    "ens = VotingClassifier(estimators = [('ensh',ens_hard),('enss',ens_soft)],voting = 'hard')\n",
    "\n",
    "ens_hard.fit(x.values,y.values)\n",
    "ens_soft.fit(x.values,y.values)\n",
    "ens.fit(x.values,y.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_submit = pd.DataFrame()\n",
    "df_submit['Survived'] = ens_hard.predict(df_test.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
